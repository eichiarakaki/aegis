---
Todos los topics deben estar 100% sincronizados, dependiendo del tamaño de los datos, un topic puede terminar de mandar todos datos mas rapido que otro al Strategy Engine, pero eso es un grave error si hay topics para más de un tipo de dato, por ejemplo un topic de klines y un topic de orderbook, tendran diferentes velocidades de envio, de nada le servidiria al strategy engine que le llegue un kline del año 2020 y a la vez un order del año 2022.

                  ||
                  vv
Dado a ese problema, he llegado a la conclusion de que un event-driven data distributor seria la mejor opcion, en vez de hacer un topic para cada tipo de dato, habra un Central Event Queue ordenado por timestamp:
Producer A ─┐
Producer B ─┼──> Central Priority Queue (min-heap por timestamp)
Producer C ─┘

Modelo determinista estricto
Todos los eventos se insertan en un heap ordenado por timestamp.
El motor siempre procesa el evento con menor timestamp disponible.
Si dos tienen mismo timestamp:
Se aplica regla de prioridad (Trade > Orderbook > Kline)
Solo después se publica al Strategy Engine y otros clientes.
Esto garantiza:
1. 100% sincronización
2. determinismo
3. reproducibilidad

---

El Strategy Engine no sera lo unico que tiene que recibir los datos, otros microservicios como el portfolio manager, risk manager, etc. tambien tienen que recibir datos para que hagan sus propias calculaciones y funciones para mantener la escalabilidad.
Entonces los componentes se tienen que agrupar por socket, pero ahi surge otro problema: 
1. Como Mercury sabra cuando todos los componentes esten conectados y listos para distribuir los datos?
2. Que pasa cuando aun mas conjunto de componentes quieren obtener datos de backtest/live? 
         ||
         VV
Solucion del 1: Subscribirse al canal de datos es algo simple, pero lo importante es saber cuando empezar a distribuir los datos, he pensado en hacer un pequeño script que actue como Trigger, que se enviará a cierto socket donde mercury esté escuchando, con eso se solucionaria el primer problema.
Solucion del 2: Dado a que actualmente esta diseñado de manera que solo habrá 1 solo socket para backtesting y live, tener mas conjuntos de componentes independientes es imposible. Como se podria solucionar:
1. Diseñar un socket TCP solo para conexiones de componentes, habrá 2 tipos: Live y Backtest
2. Mientras el script trigger(Live/Backtest) no sea ejecutado, se podran seguir agregando componentes a Live/Backtest.
3. Una vez el Trigger de Live o Backtest sea ejecutado: Se creara un proceso donde comience la distribucion de datos Y se limpiará el socket del modo ejecutado.

---

CONEXION DE COMPONENTES CON AEGIS
Los componentes primero se conectaran via el socket especial 'aegis-components.sock'
Ahí Aegis tiene que pasar las configuraciones a cada componente, que configuraciones? por ejemplo los topics que el componente requiere, el socket donde se estara streameando esos datos, etc.
Pero como lograr eso? recordemos que al conectarse a 'aegis-components.sock' el componente primero envia un payload similar a este:
# Example of expected payload: 
# {
#   component_name: "data_engine", 
#   supported_symbols: ["BTCUSDT", "ETHUSDT"], 
#   requires: ["klines", "orderbook"], 
#   supported_timeframes: ["1m", "15m", "30m", "4h", "1d"]
# }

   ||
   VV
COMO HACERLO
El objetivo de conectar los componentes al socket /tmp/aegis-components.sock es registarse en Aegis y mantener una comunicación abierta para recibir o enviar COMANDOS.
Ejemplo de comandos del componente a Aegis:
- {"COMMAND": "READY"}
- {"COMMAND": "ACK"}
- {"COMMAND": "WAIT"}
- {"COMMAND": "ERROR"}
- {"COMMAND": "FINISHED"}
Ejemplo de comandos de Aegis al componente:
- {"COMMAND": "HEARTBEAT"}
- {"COMMAND": "STARTED"}
- {"COMMAND": "WAIT"}
- {
    "data_socket": "/tmp/aegis-data-<id>.sock",
    "topics": ["klines.BTCUSDT.1m", "orderbook.BTCUSDT"]
}

Ejemplo de flujo:
1. El componente se conecta a Aegis
2. El componente envia:
{
    "data_socket": "/tmp/aegis-data-<id>.sock",
    "topics": ["klines.BTCUSDT.1m", "orderbook.BTCUSDT"]
}
3. Aegis revuelve: {"COMMAND": "ACK"}
4. El componente se conecta al data_socket y configura sus conexiones para los topics
5. El componente se subscribe a los topics
6. El componente se prepara para recibir los datos
6. El componente envia {"COMMAND": "READY"} a Aegis
7. Aegis empieza a streamear datos a los topics

---

CONEXION DE LOS COMPONENTES A SESIONES
Simplemente necesito que los componentes sepan el UUID de la sesion que se genera manualmente con el comando 'aegis session create <name> --mode <mode>'

PROBLEMA: Pero el problema es, como el componente podria saber el UUID en tiempo de ejecucion?
Una opcion seria hacer que el componente escoja a cual sesion conectarse al momento de la conexion socket, pero si hay mas de 1 sesion, como podria elegir la sesion correcta?

SOLUCION:
hacer un comando tipo: aegis session create <session_name> --mode <mode> run --path <path/to/component1> <path/to/component2>
Este comando internamente lo que hará será 
1. crear una sesión (opcional)
2. generar un SessionToken
3. correr los componentes con variables de entorno con el MISMO SessionToken generado.
Ejemplo:
{
  "component_name": "data_engine",
  "session_token": "T"
}